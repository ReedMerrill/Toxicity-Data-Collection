"""Uses Perspective API to classify toxicity."""

import time
from googleapiclient import discovery
import pandas as pd
import utils

PROJECT_PATH = "/home/reed/Projects/learned-toxicity-reddit/reddit-api/"
INPUT_PATH = f"{PROJECT_PATH}data/comments/20pct-users-subset_comments.csv"
OUTPUT_PATH = f"{PROJECT_PATH}data/comments/toxicity-classified-comments.csv"
API_KEY = "AIzaSyBQqodph6znituli74a07gc95Bq4P7TbAE"

client = discovery.build(
    "commentanalyzer",
    "v1alpha1",
    developerKey=API_KEY,
    discoveryServiceUrl="https://commentanalyzer.googleapis.com/$discovery/rest?version=v1alpha1",
    static_discovery=False,
)


def query_perspective(comments):
    """Returns a list of binarized toxicity ratings generated by Perspective
    API."""

    start = time.time()

    out_list = []
    for i, comment in enumerate(comments):
        analyze_request = {
            "comment": {"text": comment},
            "requestedAttributes": {"TOXICITY": {}},
        }

        response = client.comments().analyze(body=analyze_request).execute()
        # dig down into that crazy dictionary!
        score = response["attributeScores"]["TOXICITY"]["spanScores"][0]["score"][
            "value"
        ]
        if score >= 0.7:
            toxic = 1
        else:
            toxic = 0
        out_list.append(toxic)

        # logging
        print(f"Finished querying comment {i + 1}")
        estimate = utils.estimate_time_remaining(i, len(comments), start)
        print(f"Time remaining: ~{estimate} hours")

    return out_list


def main():

    data = pd.read_csv(INPUT_PATH)
    comments_list = list(data["text"])
    toxicity_labels = query_perspective(comments_list)
    out = pd.DataFrame({"toxic": toxicity_labels})
    with open(OUTPUT_PATH, "w") as file:
        out.to_csv(file, header=True, index=False)


if __name__ == "__main__":
    main()
